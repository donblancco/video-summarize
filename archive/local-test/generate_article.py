#!/usr/bin/env python3
"""
æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰HTMLè¨˜äº‹ã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import json
import re
import openai
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

def create_output_directories():
    """å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
    base_dir = Path("final_outputs")
    directories = [
        base_dir / "articles",
        base_dir / "metadata"
    ]
    
    for dir_path in directories:
        dir_path.mkdir(parents=True, exist_ok=True)
    
    return base_dir

def parse_transcript_file(transcript_file_path):
    """æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦æƒ…å ±ã‚’æŠ½å‡º"""
    try:
        with open(transcript_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        lines = content.split('\n')
        video_info = {}
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ã‚’è§£æ
        for line in lines[:10]:  # æœ€åˆã®10è¡Œã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
            if line.startswith('å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«:'):
                video_info['title'] = line.replace('å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«:', '').strip()
            elif line.startswith('URL:'):
                video_info['url'] = line.replace('URL:', '').strip()
            elif line.startswith('æŠ•ç¨¿è€…:'):
                video_info['uploader'] = line.replace('æŠ•ç¨¿è€…:', '').strip()
            elif line.startswith('æŠ•ç¨¿æ—¥:'):
                video_info['upload_date'] = line.replace('æŠ•ç¨¿æ—¥:', '').strip()
            elif line.startswith('å‹•ç”»æ™‚é–“:'):
                duration_str = line.replace('å‹•ç”»æ™‚é–“:', '').replace('ç§’', '').strip()
                video_info['duration'] = int(duration_str) if duration_str.isdigit() else 0
        
        # å‹•ç”»IDã‚’URLã‹ã‚‰æŠ½å‡º
        url = video_info.get('url', '')
        video_id_match = re.search(r'(?:youtube\.com/watch\?v=|youtu\.be/)([\w-]+)', url)
        video_info['id'] = video_id_match.group(1) if video_id_match else 'unknown'
        
        # æ–‡å­—èµ·ã“ã—å†…å®¹ã‚’æŠ½å‡º
        start_index = -1
        for i, line in enumerate(lines):
            if 'æ–‡å­—èµ·ã“ã—å†…å®¹' in line:
                start_index = i + 3  # ãƒ˜ãƒƒãƒ€ãƒ¼ã®å¾Œã®ç©ºè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                break
        
        if start_index > 0:
            transcript_text = '\n'.join(lines[start_index:])
        else:
            transcript_text = content
        
        return video_info, transcript_text, content
        
    except Exception as e:
        print(f"âŒ æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None, None, None

def generate_article(video_info, transcript_text):
    """æ–‡å­—èµ·ã“ã—ã‹ã‚‰è¨˜äº‹ã‚’ç”Ÿæˆ"""
    print("ğŸ“„ è¨˜äº‹ç”Ÿæˆä¸­...")
    
    # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
    client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çŸ­ç¸®ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¶é™ã‚’å›é¿
    prompt = f"""
ä»¥ä¸‹ã®YouTubeå‹•ç”»ã®æ–‡å­—èµ·ã“ã—ã‹ã‚‰ã€SEOæœ€é©åŒ–ã•ã‚ŒãŸãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«: {video_info['title']}
å‹•ç”»URL: {video_info['url']}
æŠ•ç¨¿è€…: {video_info['uploader']}

æ–‡å­—èµ·ã“ã—:
{transcript_text}

è¨˜äº‹ã®è¦ä»¶:
1. ã‚¿ã‚¤ãƒˆãƒ«ã¯å†…å®¹ã‚’çš„ç¢ºã«è¡¨ç¾ã—ã€æ¤œç´¢ã•ã‚Œã‚„ã™ã„ã‚‚ã®ã«ã™ã‚‹
2. è¦‹å‡ºã—ã‚¿ã‚°ï¼ˆh2, h3ï¼‰ã‚’é©åˆ‡ã«ä½¿ç”¨ã—ã¦æ§‹é€ åŒ–ã™ã‚‹
3. é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’ç®‡æ¡æ›¸ãã‚„è¡¨ã§ã¾ã¨ã‚ã‚‹
4. å°‚é–€ç”¨èªã«ã¯ç°¡æ½”ãªèª¬æ˜ã‚’åŠ ãˆã‚‹
5. èª­è€…ãŒè¡Œå‹•ã‚’èµ·ã“ã—ã‚„ã™ã„ã‚ˆã†ãªçµè«–ã‚’å«ã‚ã‚‹
6. æœ€å¾Œã«å‹•ç”»ãƒªãƒ³ã‚¯ã‚’å«ã‚ã‚‹ï¼ˆã€Œè©³ã—ã„è§£èª¬ã¯å‹•ç”»ã§ã”ç¢ºèªãã ã•ã„ã€ç­‰ï¼‰
7. HTMLå½¢å¼ã§å‡ºåŠ›ã™ã‚‹ï¼ˆ<!DOCTYPE html>ã‹ã‚‰</html>ã¾ã§å®Œå…¨ãªå½¢ã§ï¼‰
8. ä¸è¦ãªè¦ç´ ï¼ˆCSSã€JavaScriptã€ãƒ¡ã‚¿æƒ…å ±ç­‰ï¼‰ã¯å«ã‚ãªã„
"""
    
    try:
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯åŒ»ç™‚ãƒ»å¥åº·åˆ†é‡ã«ç²¾é€šã—ãŸãƒ—ãƒ­ã®ãƒ–ãƒ­ã‚°ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚æ­£ç¢ºã§åˆ†ã‹ã‚Šã‚„ã™ã„è¨˜äº‹ã‚’ä½œæˆã—ã¾ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=3000,
            temperature=0.7
        )
        
        article = response.choices[0].message.content
        
        # Markdownã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯è¨˜å·ã‚’é™¤å»
        if article.startswith('```html'):
            article = article[7:]  # '```html' ã‚’é™¤å»
        elif article.startswith('```'):
            article = article[3:]   # '```' ã‚’é™¤å»
        
        if article.endswith('```'):
            article = article[:-3]  # æœ«å°¾ã® '```' ã‚’é™¤å»
        
        article = article.strip()  # å‰å¾Œã®ç©ºç™½ã‚’é™¤å»
        
        print(f"âœ… è¨˜äº‹ç”Ÿæˆå®Œäº† ({len(article)}æ–‡å­—)")
        return article
        
    except Exception as e:
        print(f"âŒ è¨˜äº‹ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def generate_metadata(video_info, transcript_length, article_length):
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONã‚’ç”Ÿæˆ"""
    metadata = {
        "video_info": {
            "video_id": video_info['id'],
            "title": video_info['title'],
            "uploader": video_info['uploader'],
            "duration": video_info['duration'],
            "upload_date": video_info['upload_date'],
            "url": video_info['url'],
            "thumbnail": f"https://i.ytimg.com/vi/{video_info['id']}/maxresdefault.jpg"
        },
        "processing_info": {
            "processed_at": datetime.now().isoformat(),
            "status": "completed",
            "file_sizes": {
                "transcript_kb": transcript_length / 1024,
                "article_kb": article_length / 1024
            },
            "transcript_length": transcript_length,
            "article_length": article_length,
            "retry_count": 0
        },
        "system_info": {
            "python_version": "3.11",
            "openai_model_gpt": "gpt-4-turbo"
        }
    }
    
    return metadata

def main(transcript_file_path=None):
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ HTMLè¨˜äº‹ç”Ÿæˆé–‹å§‹")
    print("=" * 60)
    
    # å¼•æ•°ã®ç¢ºèª
    if not transcript_file_path:
        print("âŒ ã‚¨ãƒ©ãƒ¼: æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("ä½¿ç”¨æ–¹æ³•: python generate_article.py <æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹>")
        print("ä¾‹: python generate_article.py final_outputs/transcripts/transcript_VIDEO_ID_timestamp.txt")
        return
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    if not os.path.exists(transcript_file_path):
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {transcript_file_path}")
        return
    
    print(f"ğŸ“ æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«: {transcript_file_path}")
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    base_dir = create_output_directories()
    print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {base_dir}")
    
    # æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
    print("\n" + "=" * 60)
    video_info, transcript_text, full_content = parse_transcript_file(transcript_file_path)
    
    if not video_info or not transcript_text:
        print("âŒ æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    print(f"ğŸ“‹ å‹•ç”»æƒ…å ±:")
    print(f"   ã‚¿ã‚¤ãƒˆãƒ«: {video_info['title']}")
    print(f"   æŠ•ç¨¿è€…: {video_info['uploader']}")
    print(f"   å‹•ç”»ID: {video_info['id']}")
    print(f"   æ–‡å­—èµ·ã“ã—é•·: {len(transcript_text):,}æ–‡å­—")
    
    # æ–‡å­—èµ·ã“ã—ãŒé•·ã™ãã‚‹å ´åˆã¯è­¦å‘Š
    if len(transcript_text) > 4000:
        print(f"âš ï¸ æ–‡å­—èµ·ã“ã—ãŒé•·ã„ã§ã™({len(transcript_text)}æ–‡å­—)ã€‚GPT-4ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¶é™ã«ã‚ˆã‚Šã€è¨˜äº‹ç”ŸæˆãŒå¤±æ•—ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    
    # HTMLè¨˜äº‹ç”Ÿæˆ
    print("\n" + "=" * 60)
    html_content = generate_article(video_info, transcript_text)
    
    if not html_content:
        print("âŒ è¨˜äº‹ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç”Ÿæˆ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    html_file = base_dir / "articles" / f"article_{video_info['id']}_{timestamp}.html"
    html_file.write_text(html_content, encoding='utf-8')
    print(f"ğŸ“„ HTMLè¨˜äº‹ç”Ÿæˆå®Œäº†: {html_file}")
    print(f"    ğŸ“Š æ–‡å­—æ•°: {len(html_content):,}æ–‡å­—")
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
    print("\n" + "=" * 60)
    metadata = generate_metadata(video_info, len(full_content), len(html_content))
    metadata_file = base_dir / "metadata" / f"metadata_{video_info['id']}_{timestamp}.json"
    metadata_file.write_text(json.dumps(metadata, ensure_ascii=False, indent=2), encoding='utf-8')
    print(f"ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {metadata_file}")
    
    print("\n" + "=" * 60)
    print("âœ… HTMLè¨˜äº‹ç”Ÿæˆå®Œäº†ï¼")
    print("=" * 60)
    
    print(f"\nğŸ“ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"   ğŸ“„ HTMLè¨˜äº‹: {html_file}")
    print(f"   ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {metadata_file}")
    
    print(f"\nğŸŒ HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã™ã‚‹ã«ã¯:")
    print(f"   ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã„ã¦ãã ã•ã„:")
    print(f"   {html_file.absolute()}")
    
    print(f"\nğŸ“ˆ å‡¦ç†çµæœ:")
    print(f"   å‹•ç”»æ™‚é–“: {video_info['duration']}ç§’")
    print(f"   æ–‡å­—èµ·ã“ã—: {len(full_content):,}æ–‡å­—")
    print(f"   HTMLè¨˜äº‹: {len(html_content):,}æ–‡å­—")

if __name__ == "__main__":
    import sys
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®å‡¦ç†
    if len(sys.argv) == 2:
        main(sys.argv[1])
    else:
        main()